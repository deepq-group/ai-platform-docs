---
layout: editorial
---

# ðŸ§  Models

<figure><img src="../../.gitbook/assets/shutterstock_1881688810.jpg" alt=""><figcaption></figcaption></figure>

All the deep learning models you've trained reside here. You can access and oversee the models, evaluate their performance, retrain, or download them as needed.

The Model section within the DeepQ AI platform is your hub for housing and accessing AI algorithms swiftly. Here, users can easily locate and access the AI models they have trained, streamlining the process of utilizing these models for various purposes.

Users can search for and select from a repository of their trained AI models. This section also allows users to perform inference jobs, enabling them to test these models with datasets to assess their performance. If ground truth data is provided alongside the test dataset, the system automatically computes evaluation metrics specific to the type of model used.

### Model Overview





<figure><img src="../../.gitbook/assets/AI_Training_Model_Overview_Example_2.png" alt=""><figcaption></figcaption></figure>

### Model Detail



Clicking on any training task will take you to the task detail page, the information from top to bottom are:

* Task Training progress, including creation time, training duration & total GPU-hrs spent
* Training information: training dataset, model architecture and hyperparameters
* training report: real-time training accuracy & training curves (detailed pdf report downloadable)
* Dataset Statistics: Statistics of training data (training set & validation set)ï¼Œin the form of both bar charts and table.

<img src="../../.gitbook/assets/icon_option.png" alt="" data-size="line">**OPTION**: Here task owners can edit task name, stop task (only when task is running/waiting) & delete task.

<figure><img src="../../.gitbook/assets/AI_Training_Model_Detail_1.png" alt=""><figcaption></figcaption></figure>



These evaluation metrics serve as quantitative indicators of the model's performance, offering insights into its accuracy, precision, recall, and other relevant metrics. This qualitative performance assessment is invaluable for users to gauge how well their AI models are performing under different conditions and datasets.

In summary, the Model section is a convenient repository for AI models, offering quick access and enabling users to evaluate their models' performance through inference jobs while providing detailed evaluation metrics for a qualitative understanding of the model's effectiveness.



<figure><img src="../../.gitbook/assets/AI_Training_Model_Detail_2.png" alt=""><figcaption></figcaption></figure>
